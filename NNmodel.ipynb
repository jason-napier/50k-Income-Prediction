{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #numpy needs to be 1.23 or earlier in order for tf to import correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the spark dataframe df a pandas dataframe\n",
    "df = pd.read_csv(\"income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23149 entries, 0 to 23148\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             23149 non-null  int64 \n",
      " 1   workclass       23149 non-null  object\n",
      " 2   education       23149 non-null  object\n",
      " 3   marital_status  23149 non-null  object\n",
      " 4   occupation      23149 non-null  object\n",
      " 5   relationship    23149 non-null  object\n",
      " 6   race            23149 non-null  object\n",
      " 7   sex             23149 non-null  object\n",
      " 8   hours_per_week  23149 non-null  int64 \n",
      " 9   native_country  23149 non-null  object\n",
      " 10  income          23149 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[[\"age\", \"hours_per_week\"]]\n",
    "df_obj = df.drop([\"age\", \"hours_per_week\"], axis = 1)\n",
    "df_obj = df_obj.astype(str)\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df_obj))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names_out()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "df = df_num.merge(encode_df,left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out our variables\n",
    "y= df[[\"income_>50K\"]]\n",
    "X= df.drop(['income_<=50K', 'income_>50K'], axis = 1)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                2500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                312       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2897 (11.32 KB)\n",
      "Trainable params: 2897 (11.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "#optimization attempt - using more layers\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 25\n",
    "hidden_nodes_layer2 = 12\n",
    "hidden_nodes_layer3 = 6\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "#Optimization attempt - added a layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "543/543 [==============================] - 1s 981us/step - loss: 0.4161 - accuracy: 0.7925\n",
      "Epoch 2/50\n",
      "543/543 [==============================] - 1s 1ms/step - loss: 0.3624 - accuracy: 0.8268\n",
      "Epoch 3/50\n",
      "543/543 [==============================] - 1s 993us/step - loss: 0.3529 - accuracy: 0.8294\n",
      "Epoch 4/50\n",
      "543/543 [==============================] - 0s 903us/step - loss: 0.3483 - accuracy: 0.8331\n",
      "Epoch 5/50\n",
      "543/543 [==============================] - 0s 882us/step - loss: 0.3440 - accuracy: 0.8356\n",
      "Epoch 6/50\n",
      "543/543 [==============================] - 1s 977us/step - loss: 0.3410 - accuracy: 0.8378\n",
      "Epoch 7/50\n",
      "543/543 [==============================] - 1s 950us/step - loss: 0.3392 - accuracy: 0.8390\n",
      "Epoch 8/50\n",
      "543/543 [==============================] - 1s 917us/step - loss: 0.3359 - accuracy: 0.8403\n",
      "Epoch 9/50\n",
      "543/543 [==============================] - 0s 902us/step - loss: 0.3347 - accuracy: 0.8398\n",
      "Epoch 10/50\n",
      "543/543 [==============================] - 0s 906us/step - loss: 0.3324 - accuracy: 0.8425\n",
      "Epoch 11/50\n",
      "543/543 [==============================] - 0s 903us/step - loss: 0.3307 - accuracy: 0.8433\n",
      "Epoch 12/50\n",
      "543/543 [==============================] - 1s 955us/step - loss: 0.3298 - accuracy: 0.8441\n",
      "Epoch 13/50\n",
      "543/543 [==============================] - 1s 944us/step - loss: 0.3266 - accuracy: 0.8446\n",
      "Epoch 14/50\n",
      "543/543 [==============================] - 0s 874us/step - loss: 0.3255 - accuracy: 0.8449\n",
      "Epoch 15/50\n",
      "543/543 [==============================] - 0s 891us/step - loss: 0.3248 - accuracy: 0.8458\n",
      "Epoch 16/50\n",
      "543/543 [==============================] - 0s 893us/step - loss: 0.3235 - accuracy: 0.8448\n",
      "Epoch 17/50\n",
      "543/543 [==============================] - 0s 883us/step - loss: 0.3216 - accuracy: 0.8461\n",
      "Epoch 18/50\n",
      "543/543 [==============================] - 1s 945us/step - loss: 0.3204 - accuracy: 0.8464\n",
      "Epoch 19/50\n",
      "543/543 [==============================] - 0s 888us/step - loss: 0.3186 - accuracy: 0.8482\n",
      "Epoch 20/50\n",
      "543/543 [==============================] - 0s 852us/step - loss: 0.3175 - accuracy: 0.8500\n",
      "Epoch 21/50\n",
      "543/543 [==============================] - 0s 886us/step - loss: 0.3167 - accuracy: 0.8495\n",
      "Epoch 22/50\n",
      "543/543 [==============================] - 0s 909us/step - loss: 0.3154 - accuracy: 0.8493\n",
      "Epoch 23/50\n",
      "543/543 [==============================] - 1s 979us/step - loss: 0.3147 - accuracy: 0.8510\n",
      "Epoch 24/50\n",
      "543/543 [==============================] - 0s 891us/step - loss: 0.3128 - accuracy: 0.8490\n",
      "Epoch 25/50\n",
      "543/543 [==============================] - 0s 889us/step - loss: 0.3114 - accuracy: 0.8505\n",
      "Epoch 26/50\n",
      "543/543 [==============================] - 0s 867us/step - loss: 0.3106 - accuracy: 0.8510\n",
      "Epoch 27/50\n",
      "543/543 [==============================] - 0s 861us/step - loss: 0.3100 - accuracy: 0.8524\n",
      "Epoch 28/50\n",
      "543/543 [==============================] - 0s 916us/step - loss: 0.3081 - accuracy: 0.8515\n",
      "Epoch 29/50\n",
      "543/543 [==============================] - 1s 938us/step - loss: 0.3074 - accuracy: 0.8527\n",
      "Epoch 30/50\n",
      "543/543 [==============================] - 0s 879us/step - loss: 0.3072 - accuracy: 0.8524\n",
      "Epoch 31/50\n",
      "543/543 [==============================] - 0s 884us/step - loss: 0.3058 - accuracy: 0.8531\n",
      "Epoch 32/50\n",
      "543/543 [==============================] - 0s 901us/step - loss: 0.3047 - accuracy: 0.8538\n",
      "Epoch 33/50\n",
      "543/543 [==============================] - 0s 885us/step - loss: 0.3045 - accuracy: 0.8562\n",
      "Epoch 34/50\n",
      "543/543 [==============================] - 1s 950us/step - loss: 0.3020 - accuracy: 0.8563\n",
      "Epoch 35/50\n",
      "543/543 [==============================] - 0s 873us/step - loss: 0.3015 - accuracy: 0.8554\n",
      "Epoch 36/50\n",
      "543/543 [==============================] - 0s 907us/step - loss: 0.3010 - accuracy: 0.8573\n",
      "Epoch 37/50\n",
      "543/543 [==============================] - 0s 892us/step - loss: 0.3003 - accuracy: 0.8549\n",
      "Epoch 38/50\n",
      "543/543 [==============================] - 0s 871us/step - loss: 0.2994 - accuracy: 0.8567\n",
      "Epoch 39/50\n",
      "543/543 [==============================] - 1s 949us/step - loss: 0.2984 - accuracy: 0.8565\n",
      "Epoch 40/50\n",
      "543/543 [==============================] - 0s 902us/step - loss: 0.2971 - accuracy: 0.8567\n",
      "Epoch 41/50\n",
      "543/543 [==============================] - 0s 881us/step - loss: 0.2961 - accuracy: 0.8567\n",
      "Epoch 42/50\n",
      "543/543 [==============================] - 0s 890us/step - loss: 0.2966 - accuracy: 0.8546\n",
      "Epoch 43/50\n",
      "543/543 [==============================] - 0s 907us/step - loss: 0.2956 - accuracy: 0.8570\n",
      "Epoch 44/50\n",
      "543/543 [==============================] - 1s 921us/step - loss: 0.2939 - accuracy: 0.8567\n",
      "Epoch 45/50\n",
      "543/543 [==============================] - 0s 867us/step - loss: 0.2940 - accuracy: 0.8585\n",
      "Epoch 46/50\n",
      "543/543 [==============================] - 0s 859us/step - loss: 0.2933 - accuracy: 0.8582\n",
      "Epoch 47/50\n",
      "543/543 [==============================] - 0s 879us/step - loss: 0.2932 - accuracy: 0.8596\n",
      "Epoch 48/50\n",
      "543/543 [==============================] - 0s 891us/step - loss: 0.2917 - accuracy: 0.8586\n",
      "Epoch 49/50\n",
      "543/543 [==============================] - 0s 878us/step - loss: 0.2923 - accuracy: 0.8578\n",
      "Epoch 50/50\n",
      "543/543 [==============================] - 1s 952us/step - loss: 0.2910 - accuracy: 0.8588\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#Optimization attempt - increased the epochs from 25 to 50\n",
    "fit_model = nn.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 - 0s - loss: 0.4063 - accuracy: 0.8272 - 252ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.40628352761268616, Accuracy: 0.8272287249565125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(nn, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
